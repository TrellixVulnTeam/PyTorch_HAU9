{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as f\n",
    "import csv \n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_filepath = os.path.join(\"cornell movie-dialogs corpus\",\"movie_lines.txt\")\n",
    "conv_filepath = os.path.join(\"cornell movie-dialogs corpus\",\"movie_conversations.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some lines\n",
    "with open(lines_filepath,'r',encoding=\"iso-8859-1\") as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines[:8]:\n",
    "        #print(line.strip())\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting each line of the file into a dictioanry of fields (LineId,CharacterId,MovieId,Character,Text)\n",
    "line_fields = [\"lineId\",\"characterId\",\"movieId\",\"character\",\"text\"]\n",
    "lines = {}\n",
    "with open(lines_filepath,'r',encoding=\"iso-8859-1\") as f:\n",
    "    for line in f:\n",
    "        values = line.split(\" +++$+++ \")\n",
    "        # Extract fileds\n",
    "        lineobj = {}\n",
    "        for i,field in enumerate(line_fields):\n",
    "            lineobj[field] = values[i]\n",
    "            #print(lineobj)\n",
    "        lines[lineobj['lineId']] = lineobj\n",
    "        #print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groups fields of lines from 'Loadlines' into conversations based on \"movie_conversations.txt\"\n",
    "conv_fields = [\"character1Id\",\"character2Id\",\"movieId\",\"utterenceIDs\"]\n",
    "conversations = []\n",
    "with open(conv_filepath,'r',encoding='iso-8859-1') as f:\n",
    "    for line in f:\n",
    "        values = line.split(\" +++$+++ \")\n",
    "        # Extract Fields\n",
    "        convObj = {}\n",
    "        for i,field in enumerate(conv_fields):\n",
    "            convObj[field] = values[i]\n",
    "        # Convert string result from split to list, since convObj[\"utterenceIDs\"] == \"[\"L598765\",\"L567890\",\"....\"]\"\n",
    "        lineIds = eval(convObj[\"utterenceIDs\"])\n",
    "        #print(lineIds)\n",
    "        # Reassemble lines\n",
    "        convObj[\"lines\"] = []\n",
    "        for lineId in lineIds:\n",
    "            convObj[\"lines\"].append(lines[lineId])\n",
    "        conversations.append(convObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pairs of sentences from conversations\n",
    "qa_pairs = []\n",
    "for conversation in conversations:\n",
    "    # Iterate over all the lines of conversation\n",
    "    for i in range(len(conversation[\"lines\"]) - 1):\n",
    "        inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
    "        targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "        # Filter wrong samples if one of the lists is empty\n",
    "        if inputLine and targetLine:\n",
    "            qa_pairs.append([inputLine,targetLine])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " writing newly formatted file\n",
      "Done writing to the file \n"
     ]
    }
   ],
   "source": [
    "# Define path to new file\n",
    "datafile = os.path.join(\"cornell movie-dialogs corpus\",\"formatted_movie_lines.txt\")\n",
    "delimiter = '\\t'\n",
    "# Unescape the delimiter\n",
    "delimiter = str(codecs.decode(delimiter,\"unicode_escape\"))\n",
    "\n",
    "# write new csv file\n",
    "print(\"\\n writing newly formatted file\")\n",
    "with open(datafile,\"w\",encoding='utf-8') as outputfile:\n",
    "    writer = csv.writer(outputfile,delimiter=delimiter)\n",
    "    for pair in qa_pairs:\n",
    "        #print(pair[0])\n",
    "        writer.writerow(pair)\n",
    "print(\"Done writing to the file \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\tWell, I thought we'd start with pronunciation, if that's okay with you.\n",
      "\n",
      "Well, I thought we'd start with pronunciation, if that's okay with you.\tNot the hacking and gagging and spitting part.  Please.\n",
      "\n",
      "Not the hacking and gagging and spitting part.  Please.\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n",
      "\n",
      "You're asking me out.  That's so cute. What's your name again?\tForget it.\n",
      "\n",
      "No, no, it's my fault -- we didn't have a proper introduction ---\tCameron.\n",
      "\n",
      "Cameron.\tThe thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\n",
      "\n",
      "The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\tSeems like she could get a date easy enough...\n",
      "\n",
      "Why?\tUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize some Lines\n",
    "datafile = os.path.join(\"cornell movie-dialogs corpus\",\"formatted_movie_lines.txt\")\n",
    "with open (datafile,'r',encoding=\"iso-8859-1\") as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines[:8]:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0\n",
    "SOS_TOKEN = 0\n",
    "EOS_TOKEN = 2\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self,name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_TOKEN:\"PAD\",SOS_TOKEN:\"SOS\",EOS_TOKEN:\"EOS\"}\n",
    "        self.num_words = 3\n",
    "        \n",
    "    def addSentence(self,sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "            \n",
    "    def addWord(self,word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        keep_words = []\n",
    "        for k,v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "                \n",
    "        print('keep_words {}/{} = {:.4f}'.format(len(keep_words),len(self.word2index),len(keep_words)/len(self.word2index)))\n",
    "    \n",
    "        # Reinitialize the dictionaries \n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_TOKEN:\"PAD\",SOS_TOKEN:\"SOS\",EOS_TOKEN:\"EOS\"}\n",
    "        self.num_words = 3 \n",
    "        \n",
    "        for word in keep_words:\n",
    "              self.addWord(word)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a unicode string to plain ASCII\n",
    "import unicodedata\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hel'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(['h','e','l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adios,Pequeno....'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicodeToAscii(\"Adiós,Pequeño....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase, trim white spaces, lines... etc, and remove non letters character.\n",
    "import re\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    # Replace any .!? by a whitespace  + the character --> '!' = ' !'. \\1 means that first bracketed group -->[,!] .\n",
    "    # r is to not consider \\1 as a character (r to escape a backslash). + means one or more\n",
    "    s = re.sub(r\"([.!?])\",r\" \\1\",s)\n",
    "    # Remove character that is not a sequence of lower or uppercase\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\",r\" \",s)\n",
    "    # Remove a sequence of whitespace character\n",
    "    s = re.sub(r\"\\s+\",r\" \",s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aaa !s s dd ?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizeString(\"aaa123!s's   dd?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and Processing the file........... please wait\n",
      "Done Reading !!!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "datafile = os.path.join(\"cornell movie-dialogs corpus\",\"formatted_movie_lines.txt\")\n",
    "# Read the files and split into lines\n",
    "print(\"Reading and Processing the file........... please wait\")\n",
    "lines = open(datafile,encoding=\"iso-8859-1\").read().strip().split('\\n')\n",
    "# Split every line into pairs and normalize\n",
    "pairs = [[normalizeString(s) for s in pair.split('\\t')] for pair in lines]\n",
    "print(\"Done Reading !!!\")\n",
    "voc = Vocabulary(\"cornell movie-dialogs corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.',\n",
       " \"Well, I thought we'd start with pronunciation, if that's okay with you.\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0].split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns true if both sentences in a pair 'p' are under the max length threshold\n",
    "MAX_LENGTH = 10 # Maximum sentence length to consider\n",
    "def filterPair(p):\n",
    "    # Input sequences need to preserve the last word for EOS token\n",
    "    return len(p[0].split()) < MAX_LENGTH and len(p[1].split()) < MAX_LENGTH\n",
    "\n",
    "# Filter pairs using filter pair condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 221282 pairs/conversations in the dataset \n",
      "After filtering there are 64243 pairs/conversations \n"
     ]
    }
   ],
   "source": [
    "pairs = [pair for pair in pairs if len(pair) > 1]\n",
    "print(\"There are {} pairs/conversations in the dataset \".format(len(pairs)))\n",
    "pairs = filterPairs(pairs)\n",
    "print(\"After filtering there are {} pairs/conversations \".format(len(pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counted words : 18109\n",
      "['there .', 'where ?']\n",
      "['you have my word . as a gentleman', 'you re sweet .']\n",
      "['hi .', 'looks like things worked out tonight huh ?']\n",
      "['you know chastity ?', 'i believe we share an art instructor']\n",
      "['have fun tonight ?', 'tons']\n",
      "['well no . . .', 'then that s all you had to say .']\n",
      "['then that s all you had to say .', 'but']\n",
      "['but', 'you always been this selfish ?']\n",
      "['do you listen to this crap ?', 'what crap ?']\n",
      "['what good stuff ?', 'the real you .']\n"
     ]
    }
   ],
   "source": [
    "# Loop through each pair and add the question and reply e=sentence to the vocabulary\n",
    "for pair in pairs:\n",
    "    voc.addSentence(pair[0])\n",
    "    voc.addSentence(pair[1])\n",
    "print(\"counted words :\", voc.num_words)\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 7840/18106 = 0.4330\n",
      "Trimmed from 64243 pairs to 57971,0.9024 of total \n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 3   # minimum word count threshold for trimming\n",
    "def trimRareWords(voc,pairs,MIN_COUNT):\n",
    "    # Trim words used under the MIN_COUNT from the voc\n",
    "    voc.trim(MIN_COUNT)\n",
    "    # filter out paired with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_ourput = True\n",
    "        \n",
    "        # Check your sentence \n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "                \n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "                \n",
    "        # only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_ourput:\n",
    "            keep_pairs.append(pair)\n",
    "            \n",
    "    print(\"Trimmed from {} pairs to {},{:.4f} of total \".format(len(pairs),len(keep_pairs),len(keep_pairs)/len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "# Print voc and pairs\n",
    "pairs = trimRareWords(voc,pairs,MIN_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexFromSentence(voc,sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you have my word . as a gentleman'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 8, 9, 10, 4, 11, 12, 13, 2]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "indexFromSentence(voc,pairs[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there .', 'you have my word . as a gentleman', 'hi .', 'have fun tonight ?', 'well no . . .', 'then that s all you had to say .', 'but', 'do you listen to this crap ?', 'what good stuff ?', 'the real you .']\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[3, 4, 2],\n",
       " [7, 8, 9, 10, 4, 11, 12, 13, 2],\n",
       " [16, 4, 2],\n",
       " [8, 31, 22, 6, 2],\n",
       " [33, 34, 4, 4, 4, 2],\n",
       " [35, 36, 37, 38, 7, 39, 40, 41, 4, 2],\n",
       " [42, 2],\n",
       " [47, 7, 48, 40, 45, 49, 6, 2],\n",
       " [50, 51, 52, 6, 2],\n",
       " [53, 54, 7, 4, 2]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define some samples for output\n",
    "inp = []\n",
    "out = []\n",
    "for pair in pairs[:10]:\n",
    "    inp.append(pair[0])\n",
    "    out.append(pair[1])\n",
    "print(inp)\n",
    "print(len(inp))\n",
    "indexes = [indexFromSentence(voc,sentence) for sentence in inp]\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroPadding(l,fillvalue=0):\n",
    "    return list(itertools.zip_longest(*1,fillvalue=fillvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'leng' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-adc597297d12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mleng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-adc597297d12>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mleng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'leng' is not defined"
     ]
    }
   ],
   "source": [
    "leng = [leng(ind) for ind in indexes]\n",
    "max(leng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
